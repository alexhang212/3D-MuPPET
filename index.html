<!DOCTYPE html>
<html>
    <head lang="en">
        <meta charset="UTF-8">
        <meta http-equiv="x-ua-compatible" content="ie=edge">
        <meta name="author" content="Alex Chan">
        <meta name="description" content="Project page for '3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking'">
        <meta name="keywords" content="3d, pose estimation, multi-object tracking, animals, applications">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking</title>
        <link rel="stylesheet" href="html/c.css">
    </head>
    <body>
        <!-- header -->
        <section>
            <div class="container">
                <div class="row">
                    <h1 class="col-md-12 text-center">
                        <b>3D-MuPPET</b>:
                        <br>
                        <small class="h2">
                            3D Multi-Pigeon Pose Estimation and Tracking
                        </small>
                        <br>
                    </h1>
                </div>
                <hr style="margin-top:0px">
                <div class="row">
                    <div class="col-md-12 text-center">
                        <a href="mailto:urs.waldmann@uni-konstanz.de">Urs Waldmann</a><sup>1,2*</sup>, <a href="mailto:hoi-hang.chan@uni-konstanz.de">Alex Hoi Hang Chan</a><sup>2,3,4*</sup>, Hemal Naik<sup>2,4,5</sup>, Máté Nagy<sup>2,3,4,6,7</sup>, Iain D. Couzin<sup>2,3,4</sup>, Oliver Deussen<sup>1,2</sup>, Bastian Goldluecke<sup>1,2</sup> and Fumihiro Kano<sup>2,3,4</sup>
                    </div>
                </div>
                <br>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>*</sup> Contributed Equally
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>1</sup> Department of Computer and Information Science, University of Konstanz, Germany
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>2</sup> Centre for the Advanced Study of Collective Behaviour, University of Konstanz, Germany.
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>3</sup> Department of Collective Behavior, Max Planck Institute of Animal Behavior, Konstanz,
                        Germany.
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>4</sup> Department of Biology, University of Konstanz, Germany.
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>5</sup> Department of Ecology of Animal Societies, Max Planck Institute of Animal Behavior,
                        Konstanz, Germany.
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>6</sup> Department of Biological Physics, Eötvös Loránd University, Budapest, Hungary.
                    </div>
                </div>
                <div class="row">
                    <div class="col-md-12 text-center">
                        <sup>7</sup> MTA-ELTE 'Lendület' Collective Behaviour Research Group, Hungarian Academy of
                        Sciences, Budapest, Hungary.
                    </div>
                </div>


                <br>
                <div class="row">
                    <div class="col-md-2 col-md-offset-2 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="docs/Paper.pdf" target="_blank">
                                <image src="imgs/Pigeon.png" height="120px"><br>
                                    <h4><strong>Paper</strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-md-2 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="docs/Supp.pdf" target="_blank">
                                <image src="imgs/Pigeon.png" height="120px"><br>
                                    <h4><strong>Supplementary</strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>
                    <div class="col-md-2 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="https://github.com/alexhang212/3D-MuPPET" target="_blank">
                                <image src="imgs/GitHub-Mark-120px-plus.png" height="120px"><br>
                                    <h4><strong>Code</strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>
                    <!-- <div class="col-md-2 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="https://zenodo.org/record/7989831#.ZHcVyF7P0uU" target="_blank">
                                <image src="imgs/server.png" height="120px"><br>
                                    <h4><strong>Data</strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div> -->
                    <div class="col-md-2 text-center">
                        <ul class="nav nav-pills nav-justified">
                            <li>
                                <a href="https://huggingface.co/spaces/alexhang/PigeonEverywhere" target="_blank">
                                <image src="imgs/hf-logo.png" height="120px"><br>
                                    <h4><strong>Hugging Face Demo</strong></h4>
                                </a>
                            </li>
                        </ul>
                    </div>

                </div>
            </div>
        </section>
        <!-- news -->
        <section>
            <div class="container">
                <div class="row">
                    <h3 class="col-md-12 text-center">
                        <b>News</b>
                    </h3>
                                    <div class="row">
                    <div class="col-md-12 text-left">
                    <b>2023/10/13</b> We have officially launched our project site, and launched our hugging face demo for 2D posture estimation of pigeons in any environments [<a href="https://huggingface.co/spaces/alexhang/PigeonEverywhere" target="_blank">Hungging Face</a>].
                    </div>
        </section>
        <!-- abstract -->
        <section>
            <div class="container">
                <div class="row">
                    <h3 class="col-md-12 text-center">
                        <b>Abstract</b>
                    </h3>
                </div>
                <hr style="margin-top:0px">
                <div class="row">
                    <div class="col-md-12">
                        <img src="imgs/framework.png" alt="3D-MuPPET Framework" style="width:100%">
                    </div>
                </div>
                <br>
                <div class="row">
                    <div class="col-md-12 text-left">
                    Markerless methods for animal posture tracking have been developing recently, but frameworks and benchmarks for tracking large animal groups in 3D are still lacking. To overcome this gap in the literature, we present 3D-MuPPET, a framework to estimate and track 3D poses of up to 10 pigeons at interactive speed using multiple-views. We train a pose estimator to infer 2D keypoints and bounding boxes of multiple pigeons, then triangulate the keypoints to 3D. For correspondence matching, we first dynamically match 2D detections to global identities in the first frame, then use a 2D tracker to maintain correspondences accross views in subsequent frames. We achieve comparable accuracy to a state of the art 3D pose estimator for Root Mean Square Error (RMSE) and Percentage of Correct Keypoints (PCK). We also showcase a novel use case where our model trained with data of single pigeons provides comparable results on data containing multiple pigeons. This can simplify the domain shift to new species because annotating single animal data is less labour intensive than multi-animal data. Additionally, we benchmark the inference speed of 3D-MuPPET, with up to 10 fps in 2D and 1.5 fps in 3D, and perform quantitative tracking evaluation, which yields encouraging results. Finally, we show that 3D-MuPPET also works in natural environments without model fine-tuning on additional annotations. To the best of our knowledge we are the first to present a framework for 2D/3D posture and trajectory tracking that works in both indoor and outdoor environments.                    </div>
                </div>
            </div>
        </section>
        <!-- additional results -->
        <section>
            <div class="container">
                <div class="row">
                    <div class="col-md-12 text-center">
                        <h3>
                            <b>Additional Results</b>
                        </h3>
                    </div>
                </div>
                <hr style="margin-top:0px">
                <div class="row">
                    <div class="col-md-12">
                        <h4>
                            <b>3D Pose Estimation and Tracking of Multiple Pigeons in Captive Environments</b>
                        </h4>
                        <p>Using the 3D-POP dataset, we trained 2D keypoint detection models, then triangulated postures into 3D. We also show that models trained on single pigeon data also work well with multi-pigeon data.</p>
                        <br>
                        <p>This video shows 3D keypoints from triangulation, reprojected to a single camera view.</p>
                        <video id="v0" width="100%" autoplay loop muted controls>
                            <source src="videos/BarnSample.mp4" type="video/mp4" />
                        </video>
                        <br><br>
                        <p>This video shows 3D pose estimations of 10 foraging pigeons.</p>
                        <video id="v0" width="100%" autoplay loop muted controls>
                            <source src="videos/black.mp4" type="video/mp4" />
                        </video>
                        <p><br><br><b>Pigeons in outdoor environments.</b> Using the segment anything model, we trained a 2D keypoint detector with masked pigeons from captive data, then applied the model to pigeon videos outdoors for 3D tracking in the wild.</p>
                        <video id="v0" width="100%" autoplay loop muted controls>
                            <source src="videos/wild.mp4" type="video/mp4" />
                        </video>

                    </div>
                </div>

            </div>
        </section>
        <!-- citation -->
        <section>
            <div class="container">
                <div class="row">
                    <div class="col-md-12 text-center">
                        <h3>
                            <b>Cite us</b>
                        </h3>
                    </div>
                </div>
                <hr style="margin-top:0px">
                <div class="row">
                    <div class="col-md-12">
                        <pre style="background-color: #e9eeef">
                            <code>
    @article{waldmann20233d,
      title={3D-MuPPET: 3D Multi-Pigeon Pose Estimation and Tracking},
      author={Waldmann, Urs and Chan, Alex Hoi Hang and Naik, Hemal and Nagy, M{\'a}t{\'e} and Couzin, Iain D and Deussen, Oliver and Goldluecke, Bastian and Kano, Fumihiro},
      journal={arXiv preprint arXiv:2308.15316},
      year={2023}
    }  
                            </code>
                        </pre>
                    </div>
                </div>
            </div>
        </section>
        <!-- footer -->
        <footer class="text-center" style="margin-bottom:10px">
            <a href="https://alexhang212.github.io/3D-MuPPET/" target="_blank">3D-MuPPET</a> is maintained by <a href="https://alexhhchan.odoo.com/" target="_blank">Alex Chan</a> and <a href="https://urs-waldmann.de/computer-vision/" target="_blank">Urs Waldmann</a>.
        </footer>
    </body>
</html>
